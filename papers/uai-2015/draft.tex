\documentclass[]{article}
\usepackage{proceed2e}

% Set the typeface to Times Roman
\usepackage{times}


% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
%\usepackage{subcaption} 
%usepackage[numers]{natbib}
% For citations
%\usepackage[numbers]{natbib}

% For algorithms
%\usepackage{algorithm}
%\usepackage{algorithmic}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2014} with
% \usepackage[nohyperref]{icml2014} above.
%\usepackage{hyperref}
% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
%\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{bm}
\usepackage{amsmath}
%\usepackage{array}
%\usepackage{nips_style} 
%\usepackage{sidecap}
%\usepackage[export]{adjustbox}
%\include{cdefs}

% Leave date blank
\date{}

\pagestyle{myheadings}
%\usepackage{sidecap}
%\usepackage[export]{adjustbox}

%\newcommand{\theHalgorithm}{\arabic{algorithm}}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\input{cdefs}


\title{Likelihood-free Inference and Optimization \\ using Stochastic Gradient Approximations}

\author{} % LEAVE BLANK FOR ORIGINAL SUBMISSION.
          % UAI  reviewing is double-blind.
          
% \author{
% Edward Meeds \\
% Informatics Institute \\
% University of Amsterdam \\
% \texttt{tmeeds@gmail.com} \\
% \and
% \author{
% Robert Leenders \\
% Informatics Institute \\
% University of Amsterdam \\
% \texttt{robert.leenders@student.uva.nl} \\
% \and
% Max Welling \\
% Informatics Institute\\
% University of Amsterdam \\
%  \texttt{welling.max@gmail.com}
% }
%\nipsfinalcopy
\begin{document} 
	\vskip -0.3in
  
\maketitle

% 
% 
% \begin{abstract} 
% \input{abstract}
% \end{abstract} 
\begin{abstract} 
In this paper we apply recent techniques from Bayesian inference that use gradient information to sample efficiently from the true posterior distribution to the {\em likelihood-free} or {\em approximate Bayesian computation} (ABC) setting.  To do this for ABC we adopt a {\em gradient-free} stochastic approximation algorithm by Spall~\cite{spall1999}.  Together these algorithms provide both optimization and inference for likelihood-free models as the algorithm ABC-SGLD transitions from optimization to sampling.  We demonstrate ABC-SGLD on problems where the true gradient information is known and on challenging ABC simulators.
\end{abstract} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION} \label{introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
  \item  Arguably the two most useful procedures in simulation-based science are optimization and Bayesian inference.  
  \item  Optimization can take the form of simple grid-search to sophisticated techniques like factorial design \cite{factorialdesign}, Bayesian experiment design \cite{bayesexpdesign}, (mention others).
  \item Recently, Bayesian optimization techniques have shown success in optimizing very expensive black-box simulators \cite{bosuccess}.
  \item The main approach of Bayesian inference of simulator parameters is ABC.  ABC is largely based a few sampling algorithms: SMC and MCMC.  
  \item Though gradients are not directly computable for simulators, they can be computed analytically by using finite differences (see \cite{kiefer1952}).  This quickly becomes infeasible for large $p$ problems.  There is however an alternative stochastic approximation algorithm by Spall \cite{spall1999} that requires only 2 simulation calls independent of $p$.  
  \item By using this approximation, gradient-based algorithms can be adopted for simulators: for optimization, using analogous stochastic gradient descent algorithms and for Bayesian inference using Langevin dynamics \cite{langevin}.
  \item Recently, the SGLD \cite{wellingsgld} algorithm has efficiently combined optimization with inference using ideas from SGD with Langevin dynamics.
  \item This paper describes ABC-SGLD.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{GRADIENTS FROM FORWARD SIMULATIONS} \label{gradsforward}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Robbin's Monro: SGD}




\subsection{Spall's method: SPSA}
In the gradient-free setting, Spall \cite{spall_spsa} provides a stochastic approximate to the true gradient using only 2 forward simulations (function evaluations).  This is in contrast to multivariate finite-difference stochastic approximation FDSA \cite{kiefer1952} requiring $2p$ evaluations.  

The gradient estimate is
\begin{equation}
  \gradestimate{t}{\thetav_t} = \begin{bmatrix} 
                                   \frac{\feval{t}{+} - \feval{t}{-}}{2 \cstep{t}{1} \dstep{t}{1}} \\
                                   \vdots \\
                                   \frac{\feval{t}{+} - \feval{t}{-}}{2 \cstep{t}{p} \dstep{t}{p}} \\
                                \end{bmatrix}
\end{equation}
where $\cstep{t}{p}$ is a step-size that is usually constant for all dimensions $p$, but can be different (as shown in this case); $\dstep{t}{p} \in {-1, +1}$ is a {\em perturbation mask} (called symmetric Bernouilli variables by Spall), i.e. $\dstep{t}{p} \sim 2*\text{Bernouilli}(0.5) - 1$; and  $\feval{t}{\pm}$ are function evaluations:
\begin{eqnarray}
  \feval{t}{+} &= \loglik{\thetav + \cstepconst{t}\dstepconst{t}} \\
  \feval{t}{-} &= \loglik{\thetav - \cstepconst{t}\dstepconst{t}}
\end{eqnarray}
A way of reducing the noise in the gradient is by averaging over $q$ draws of $\dstepconst{t}$:
\begin{equation}
  \gradestimate{t}{\thetav_t} = \frac{1}{q} \sum_{j=1}^q \gradestimaterepeat{t}{\thetav_t}{j}
\end{equation}
where for each $j$ new perturbation masks are drawn.  

Another variance reduction technique called the method of {\em common random numbers} (CRN) \cite{kleinman1999} sets a common seed for the random number generator (RNG) for both calls to the simulator.  This technique can remove the effect of the simulator noise in the gradient estimate, leaving on the randomness of the perturbation masks as the source of noise. Consider using SPSA instead of SGD: the CRN technique is equivalent of using the same batch of data vectors to evaluate the log-likelihood which is a sensible approach.

\subsubsection{Variations}

\begin{itemize}
\item Varying $c_q$: use a different per repeat.  Seems to converge faster.  What is the correct noise process?  Right now trying this: flip coin, if heads perturb $c *= 1+U(0,1)$, else perturb $c /= 1 + U(0,1)$. 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{LANGEVIN DYNAMICS} \label{ld}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{STOCHASTIC-GRADIENT LD} \label{sgld}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{eqnarray}
  h & = & \frac{N}{n} \sum_{i=1}^n \nabla \log p(\bx_i | \thetav)- \sum_{i=1}^N \nabla \log p(\bx_i | \thetav ) \\
    & = & \frac{N}{n} \sum_{i=1}^n s_i \\
  s_i & = & \nabla \log p(\bx_i | \thetav) + \frac{1}{N} \nabla p(\thetav) \\
  \text{V}(h) & = & \frac{N^2}{n^2} \sum_{i=1}^n \text{Var}(s_i) \\
                & = & \frac{N^2}{n^2} \sum_{i=1}^n \frac{1}{n} \lp \sum_{j=1} (s_i - \bar{s})^2 \rp \\
                & = & \frac{N^2}{n^2} \sum_{i=1}^n V_s \\
                & = & \frac{N^2}{n^2} n V_s \\
                & = & \frac{N^2}{n} V_s 
  %\text{Var}(\thetav) & = & \frac{\epsilon^2}{4}\text{Var}(h) + \epsilon \\
  %       \frac{\epsilon^2}{4}\text{Var}(h) & << & \epsilon \\
  %       \frac{\epsilon N^2}{4 n} V_s & << & 1       
\end{eqnarray}
\begin{eqnarray}
  \text{Var}(\thetav) & = & \frac{\epsilon^2}{4}\text{Var}(h) + \epsilon \\
         \frac{\epsilon^2}{4}\text{Var}(h) & << & \epsilon \\
         \frac{\epsilon N^2}{4 n} V_s & << & 1       
\end{eqnarray}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SGLD-ABC} \label{sgld}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{ABC Cost Function}

The ABC likelihood is proportional to the convolution between a kernel around the observation statistics $\y$ and the generator of pseudo-statistics $\x$, i.e. the simulator.  Since pseudo-statistics can only be generated, we resort to a Monte Carlo estimate for the ABC likelihood based on $S$ draws from the simulator using the same parameter vector $\thetav$ but different random seeds:
\begin{eqnarray}
  \pi\lp \y | \thetav \rp & = &  \int \pi_{\epsvec}\lp \y | \x \rp \pi\lp \x | \thetav \rp d \x \\
   & \approx & \frac{1}{S} \sum_{s=1}^S \pi_{\epsvec}\lp \y | \x^{(s)} \rp
\end{eqnarray}
where $\x^{(s)} = \pi\lp \x | \thetav, \omega_s \rp$.  Note we have passed a unique random seed $\omega_s$ into the simulator, making $\x^{(s)}$ a deterministic function of the simulator with parameters $\{\thetav, \omega_s\}$.  It will be useful to rewrite this deterministic simulator function as $f$: $\x^{(s)} = f\lp \thetav, \omega_s \rp$, allowing us to rewrite the likelihood as
\begin{eqnarray}
  \pi\lp \y | \thetav \rp & \approx & \frac{1}{S} \sum_{s=1}^S \pi_{\epsvec}\lp \y | f\lp \thetav, \omega_s \rp \rp
\end{eqnarray}

For optimization purposes we can search for the maximum a posteriori (MAP) estimator $\hat{\thetav}$ using the log-joint distribution $\hat{\thetav} = \argmax_{\thetav} \mathcal{MAP}$, where $\mathcal{MAP}$ is
\begin{eqnarray}
  \mathcal{LJ} &    =    & \log \pi(\thetav) + \log \pi\lp \y | \thetav \rp \\
                & \approx &\log \pi(\thetav) + \log \sum_{s=1}^S \pi_{\epsvec}\lp \y | f\lp \thetav, \omega_s \rp \rp - \log S
\end{eqnarray} 
we can also maximize the lower-bound of $\mathcal{LJ} \geq \mathcal{LB}$, where 
\begin{eqnarray}
  \mathcal{LB} & \approx &\log \pi(\thetav) + \sum_{s=1}^S \log  \pi_{\epsvec}\lp \y | f\lp \thetav, \omega_s \rp \rp
\end{eqnarray} 
which will be more convenient for optimization for typical kernels (i.e. $\pi_{\epsilon}$ is Gaussian).

The simplest optimization is to set the objective function  $C$ to be $-\mathcal{LJ}$ or $-\mathcal{LB}$ and compute stochastic gradients using 2SPSA with $q$ repeats (negative log-likelihood because we will assume minimization):
\begin{eqnarray}
  \frac{\partial C}{\partial \thetav} & = & \frac{1}{q} \sum_{j=1}^{q} \frac{C\lp \thetav + c \Delta_j\rp - C{\lp\thetav - c \Delta_j\rp}}{2 c \Delta_j}
\end{eqnarray}
or 1SPSA
\begin{eqnarray}
  \frac{\partial C}{\partial \thetav} & = & \frac{1}{q} \sum_{j=1}^{q}  \frac{C\lp \thetav + c \Delta_j\rp - C(\thetav)}{c \Delta_j}
\end{eqnarray}
which is less accurate but is less computation if $C(\thetav)$ is computed at each step (TODO: possible algorithm).  TODO: rewrite $\frac{\partial C}{\partial \thetav}$ as $\hat{g}$ or similar.

\subsection{Special Case: Gaussian Kernels}
When the kernel is known we can use the chain rule to compute the gradients with the first part from the kernel and the second from the variation of the simulator pseudo-statistics, whose gradient can be estimated using SPSA.  Expanding the likelihood over $J$ statistics, the lower bound on the loglikelihood becomes:
\begin{eqnarray}
  \hat{L} & = & \sum_s \log \pi_{\epsilon}\lp \y | f(\thetav, \omega_s)\rp \\
          & = & \sum_s \log \prod_{j=1}^J \pi_{\epsilon_j}\lp y_j | f_j(\thetav, \omega_s)\rp \\
          & = & \sum_s \sum_j \log  \pi_{\epsilon_j}\lp y_j | f_j(\thetav, \omega_s)\rp \\
          & = & \sum_s \sum_j -\frac{1}{2} \frac{\lp y_j - f_j(\thetav, \omega_s)\rp^2}{\epsilon_j^2} - Z_j \\
\end{eqnarray}

The gradient:
\begin{eqnarray} 
  \nabla \hat{L} & = & \sum_s \sum_j \frac{\lp y_j - f_j(\thetav, \omega_s)\rp}{\epsilon_j^2} \cdot \frac{\partial f_j(\thetav, \omega_s)}{\partial \thetav} \\
                 & = & \sum_s \sum_j e_{js} \nabla_{js}
\end{eqnarray}
The first part $e_{js}$ is analytic, the second part $\nabla_{js}$ requires estimation by 2SPSA:
\begin{eqnarray} 
  \hat{ \nabla }_{js}  & = & \frac{1}{q} \sum_{r=1}^q \frac{f_j(\thetav + c \Delta_r , \omega_s) - f_j(\thetav - c \Delta_r , \omega_s)}{2 c \Delta_r}
\end{eqnarray}
or 1SPSA
\begin{eqnarray} 
  \hat{ \nabla }_{js} & = & \frac{1}{q} \sum_{r=1}^q \frac{f_j(\thetav + c \Delta_r , \omega_s) - f_j(\thetav, \omega_s)}{c \Delta_r}
\end{eqnarray}
the benefit of 1SPSA in this case is that the first gradients  $e_{js}$ can be computed from $f_j(\thetav, \omega_s)$.

\subsection{SGD, AdaGrad, RMSProp, AdaM}

With our stochastic gradient in hand, we can make use of robust stochastic gradient rules, including recent advances from machine learning.  

\subsubsection{SGD}
The basic update rule is at time $t$ for minimization is
\begin{eqnarray}
  \Delta\thetav & = & - \alpha_t \hat{g_t}
\end{eqnarray} 
with conditions $\sum_{t=1}^{\infty} \alpha_t = \infty$ and $\sum_{t=1}^{\infty} \alpha_t^2 < \infty$ required for convergence.
An additional momentum parameter $\beta_1$ can be added to improve convergence
\begin{eqnarray}
  \gmom & = & \beta_1 \gmom + (1-\beta_1)*\hat{g_t} \\
  \Delta\thetav & = & - \alpha_t \gmom
\end{eqnarray}

\subsubsection{AdaGrad}
AdaGrad uses the total cumulative element-wise square of the gradients to automatically both decrease $\alpha_t$ and scale the learning rates for each dimension: 
\begin{eqnarray}
  \gmom    & = & \beta_1 \gmom + (1-\beta_1)*\hat{g_t} \\
  \gsquare & = & \sum_{t'=1}^t \hat{g_t}^2 \\
  \Delta\thetav & = & - \alpha_t \gmom / \sqrt{\gsquare}
\end{eqnarray}

\subsubsection{RMSProp}
\begin{eqnarray}
  \gmom    & = & \beta_1 \gmom + (1-\beta_1)*\hat{g_t} \\
  \gsquare & = & \beta_2 \gsquare + (1-\beta_2)*\hat{g_t}^2 \\
  \Delta\thetav & = & - \alpha_t \gmom / \sqrt{\gsquare}
\end{eqnarray}

\subsubsection{AdaM}
\begin{eqnarray}
  \gmom    & = & \beta_1 \gmom + (1-\beta_1)*\hat{g_t} \\
  \gsquare & = & \beta_2 \gsquare + (1-\beta_2)*\hat{g_t}^2 \\
  \gamma & = & \frac{ \sqrt{1-(1-\beta_2)^t}}{(1-(1-\beta_1)^t)} \\
  \Delta\thetav & = & - \alpha_t \gamma \gmom / \sqrt{\gsquare}
\end{eqnarray}

\section{Applying SGLD to ABC}

There are two main sources of randomness in the ABC gradient computation: the random perturbation mask and the random seed of the simulator model, which controls the simulator noise.  This noise can be eliminated by using common random numbers \cite{spall-crn}.  On the other hand, it is not clear that this is the best strategy, as the noise from the masks at a fixed seed may be higher than   

\begin{eqnarray}
  V_{\gradestimaterepeat{t}{\thetav_t}{j}} & = & \frac{1}{q-1} \sum_{j=1}^q (\gradestimaterepeat{t}{\thetav_t}{j} - \gradestimate{t}{\thetav_t})^2 \\
  V_{\gradestimate{t}{\thetav_t}} & = & \frac{1}{q-1} V_{\gradestimaterepeat{t}{\thetav_t}{j}} \\
  \frac{\epsilon^2}{4 }V_{\gradestimate{t}{\thetav_t}} & = & \frac{\epsilon^2}{4 q }V_{\gradestimaterepeat{t}{\thetav_t}{j}} \\
                                                       & << & \epsilon \\
                    \frac{\epsilon}{4 (q-1) }V_{\gradestimaterepeat{t}{\thetav_t}{j}}  & << & 1                                  
\end{eqnarray}

Check for $g(\thetav) + h(\thetav) + \eta$ that $h(\thetav) + \eta \approx \eta$

Also $\theta_{t+1} = \theta_t + \frac{\epsilon}{2}\gradestimate{t}{\thetav_t} + \sqrt{\epsilon}\mathcal{N}(0,1)$

\subsection{Statistical Tests for Gradients}

From Byrd:
\begin{eqnarray}
\frac{||V_{\gradestimaterepeat{t}{\thetav_t}{j}} ||_1}{q} & \leq r^2 || \hat{g}_t ||_2^2 \\
\hat{q} & = & \frac{||V_{\gradestimaterepeat{t}{\thetav_t}{j}} ||_1}{r^2 || \hat{g}_t ||_2^2}
\end{eqnarray}

TODO:
\begin{itemize}
  \item Check that $q$ gradients are normal.  Especially as $q$ increases.
  \item Merge Byrd's test for $\hat{q}$ and condition on SGLD-ABC.
  \item Variance check for increasing $q$ can also be used to stop optimization since the variance is less than the noise in the gradients.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EXPERIMENTS} \label{experiments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Logistic Regression with Stochastic Gradients}

\subsection{Optimization of Blowfly Dynamics}

\subsubsection{Using AdaM}

\begin{figure}[h]
\vspace{1in}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_post_series.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_post_series_sgld5k.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_post.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_post_sgld5k.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_postpred_series.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_postpred_series_sgld5k.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_postpred.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_postpred_sgld5k.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_noise.png}
\includegraphics[width=0.45\columnwidth]{./images/blowfly_adam_noise_sgld5k.png}
\caption{Optimizing Blowfly using $q=5$, $\epsilon = 0.01$, $\beta_1=0.75$,$\beta_2=0.9$,$\alpha=0.1$ and $c=1$.  Left: Optimization using AdaM, Right: ``SGLD'' with estimated noise. }
\end{figure}

\subsubsection{Using AdaM with ``SGLD" injected noise}

\subsection{Likelihood-free Inference of Blowfly Dynamics}

\subsection{Other Useful ABC problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{DISCUSSION} \label{discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSION} \label{conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{References}
\newpage
{
\bibliographystyle{abcsgld}
}

\end{document}